basic {
  max_span_width = 20
  no_cuda = false
  report_frequency = 500
  gradient_checkpointing = false

  # Learning-Related Configs
  epochs = 50
  transformer_learning_rate = 5e-05
  task_learning_rate = 0.0001
  dropout_rate = 0.3
  batch_size = 32
  max_grad_norm = 1.0
  ned_pretrain_epochs = 1

  # Architecture-Related Configs
  feature_size = 20
  span_emb_size = 500
  transformer = allenai/scibert_scivocab_cased

  mention_scorer_ffnn_size = 500
  mention_scorer_ffnn_depth = 2

  mention_linker_ffnn_size = 500
  mention_linker_ffnn_depth = 2

  # Configs related to external knowledge
  use_external_knowledge = false
}

with_external_knowledge = ${basic} {
  use_external_knowledge = true
  span_emb_size = 512
  dropout_rate = 0.2
  span_ratio = 0.5
  task_learning_rate = 0.0001
  # task_learning_rate = 0.0002 for biorelex

  # GNN for External Knowledge Graph
  ekg_gnn_hidden_layers = 3
  ekg_gnn_num_bases = -1
  ekg_gnn_dropout = 0.1

  # BiGNN for Prior IE Graph
  ieg_bignn_dropout = 0.1
  ieg_bignn_hidden_layers = 2
}

# BioBERT
biobert = ${basic} {
  transformer = dmis-lab/biobert-large-cased-v1.1
}

biobert_with_external_knowledge = ${biobert} {
  use_external_knowledge = true
}
